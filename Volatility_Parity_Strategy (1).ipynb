{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Volatility Parity Strategy"
      ],
      "metadata": {
        "id": "XXnKF_-tevBC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Abstract\n",
        "\n",
        "This Volatility Parity (VolParity) investment strategy aims to construct a risk-balanced portfolio by allocating capital such that each asset contributes equally to the overall portfolio volatility. Unlike traditional portfolios that allocate based on notional weights or expected returns, Volatility Parity targets a pre-specified level of total portfolio risk and adjusts exposures dynamically based on the assets' recent observed volatilities. This results in a more diversified and stable risk allocation, potentially offering improved risk-adjusted returns and reduced drawdowns, especially during periods of market stress. The strategy is particularly suited for multi-asset portfolios encompassing equities, bonds, credit, and commodities."
      ],
      "metadata": {
        "id": "m_C2Enyibj9Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Methodology\n",
        "\n",
        "### Data:\n",
        "The strategy uses a selection of liquid ETFs representing major asset classes: U.S. equities (SPY, QQQ), emerging markets (EEM), U.S. Treasury bonds (TLT, IEF), corporate and high-yield credit (LQD, HYG), and gold (GLD).\n",
        "\n",
        "### Return and Volatility Estimation:\n",
        "\n",
        "Returns are computed using log returns on daily price data.\n",
        "Each asset’s volatility is estimated via an exponentially weighted moving average (EWMA) over a rolling window (span = 30 or 60 days).\n",
        "\n",
        "Weight Construction:\n",
        "Asset weights are set inversely proportional to their estimated volatility\n",
        "Weights are normalized to sum to 1 across the portfolio.\n",
        "The entire portfolio is scaled to target a predefined annualized volatility (15%).\n",
        "\n",
        "### Backtesting & Rebalancing:\n",
        "\n",
        "The portfolio is rebalanced with a 1-day implementation lag.\n",
        "Transaction costs are incorporated (10 bps per round-trip).\n",
        "Historical backtests generate performance statistics and risk metrics.\n",
        "\n",
        "A comprehensive strategy factsheet is created, showing cumulative returns, volatility, drawdowns, turnover, and comparison against benchmarks ( SPY, TLT). Group-level exposures and P&L decomposition are visualized based on asset class groupings.\n",
        "\n"
      ],
      "metadata": {
        "id": "Z0QoRxeKbzdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qis"
      ],
      "metadata": {
        "id": "NgTUADKam_Nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Tuple, List\n",
        "from enum import Enum\n",
        "import yfinance as yf\n",
        "import qis\n",
        "from qis import TimePeriod, PortfolioData\n",
        "from qis.portfolio.reports.config import fetch_default_report_kwargs\n",
        "\n",
        "def safe_download(tickers: List[str], start: str = '2005-01-01') -> pd.DataFrame:\n",
        "    valid_prices = {}\n",
        "    for ticker in tickers:\n",
        "        try:\n",
        "            df = yf.download(ticker, start=start, progress=False, ignore_tz=True)['Close']\n",
        "            if not df.empty:\n",
        "                valid_prices[ticker] = df\n",
        "            else:\n",
        "                print(f\"⚠️ No data for ticker: {ticker}\")\n",
        "        except Exception as e:\n",
        "            print(f\" Failed to download '{ticker}': {e}\")\n",
        "\n",
        "    if not valid_prices:\n",
        "        raise ValueError(\" All ticker downloads failed. Check internet connection or symbols.\")\n",
        "\n",
        "    prices_df = pd.concat(valid_prices.values(), axis=1)\n",
        "    prices_df.columns = list(valid_prices.keys())\n",
        "    return prices_df\n",
        "\n",
        "def fetch_universe_data() -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series]:\n",
        "    universe_data = dict(SPY='Equities',\n",
        "                         QQQ='Equities',\n",
        "                         EEM='Equities',\n",
        "                         TLT='Bonds',\n",
        "                         IEF='Bonds',\n",
        "                         LQD='Credit',\n",
        "                         HYG='HighYield',\n",
        "                         GLD='Gold')\n",
        "\n",
        "    tickers = list(universe_data.keys())\n",
        "    group_data = pd.Series(universe_data)\n",
        "\n",
        "    prices = safe_download(tickers)\n",
        "    prices = prices.asfreq('B', method='ffill')\n",
        "\n",
        "    available = [t for t in ['SPY', 'TLT'] if t in prices.columns]\n",
        "    if len(available) < 2:\n",
        "        print(\"⚠️ Benchmark components missing. Using first two available tickers as benchmark.\")\n",
        "        available = list(prices.columns[:2])\n",
        "    benchmark_prices = prices[available]\n",
        "\n",
        "    return prices, benchmark_prices, group_data.loc[prices.columns]\n",
        "\n",
        "def fetch_equity_bond() -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series]:\n",
        "    universe_data = dict(SPY='Equities', IEF='Bonds')\n",
        "    tickers = list(universe_data.keys())\n",
        "    group_data = pd.Series(universe_data)\n",
        "    prices = safe_download(tickers)\n",
        "    benchmark_prices = prices.loc[:, prices.columns.intersection(['SPY', 'IEF'])]\n",
        "    return prices, benchmark_prices, group_data.loc[prices.columns]\n",
        "\n",
        "def generate_volparity_portfolio(prices: pd.DataFrame,\n",
        "                                 group_data: pd.Series,\n",
        "                                 time_period: TimePeriod = None,\n",
        "                                 span: int = 60,\n",
        "                                 vol_target: float = 0.15,\n",
        "                                 rebalancing_costs: float = 0.0010) -> PortfolioData:\n",
        "    if prices.empty:\n",
        "        raise ValueError(\"Price data is empty. Cannot generate portfolio.\")\n",
        "\n",
        "    returns = qis.to_returns(prices=prices, is_log_returns=True)\n",
        "    if returns is None or not isinstance(returns, pd.DataFrame) or returns.empty:\n",
        "        raise ValueError(\"Return series is missing or invalid after conversion.\")\n",
        "\n",
        "    ra_returns, weights, ewm_vol = qis.compute_ra_returns(returns=returns,\n",
        "                                                          span=span,\n",
        "                                                          vol_target=vol_target)\n",
        "    weights = weights.divide(weights.sum(1), axis=0)\n",
        "\n",
        "    if time_period is not None:\n",
        "        weights = time_period.locate(weights)\n",
        "\n",
        "    portfolio = qis.backtest_model_portfolio(prices=prices,\n",
        "                                             weights=weights,\n",
        "                                             rebalancing_costs=rebalancing_costs,\n",
        "                                             weight_implementation_lag=1,\n",
        "                                             ticker='VolParity')\n",
        "    portfolio.set_group_data(group_data=group_data, group_order=list(group_data.unique()))\n",
        "    return portfolio\n",
        "\n",
        "def generate_equity_bond_portfolio(prices: pd.DataFrame,\n",
        "                                   weights: List[float],\n",
        "                                   group_data: pd.Series,\n",
        "                                   rebalancing_costs: float = 0.0010) -> PortfolioData:\n",
        "    portfolio = qis.backtest_model_portfolio(prices=prices,\n",
        "                                             weights=weights,\n",
        "                                             rebalancing_costs=rebalancing_costs,\n",
        "                                             ticker='EquityBond')\n",
        "    portfolio.set_group_data(group_data=group_data, group_order=list(group_data.unique()))\n",
        "    return portfolio\n",
        "\n",
        "class UnitTests(Enum):\n",
        "    VOLPARITY_PORTFOLIO = 1\n",
        "    EQUITY_BOND = 2\n",
        "    DELTA1_STRATEGY = 3\n",
        "\n",
        "def run_unit_test(unit_test: UnitTests):\n",
        "    time_period = TimePeriod('31Dec2005', '21Apr2025')\n",
        "    rebalancing_costs = 0.0010\n",
        "\n",
        "    if unit_test == UnitTests.VOLPARITY_PORTFOLIO:\n",
        "        prices, benchmark_prices, group_data = fetch_universe_data()\n",
        "        portfolio_data = generate_volparity_portfolio(prices=prices,\n",
        "                                                      group_data=group_data,\n",
        "                                                      time_period=time_period,\n",
        "                                                      span=30,\n",
        "                                                      vol_target=0.15,\n",
        "                                                      rebalancing_costs=rebalancing_costs)\n",
        "        figs = qis.generate_strategy_factsheet(portfolio_data=portfolio_data,\n",
        "                                               benchmark_prices=benchmark_prices,\n",
        "                                               time_period=time_period,\n",
        "                                               add_current_position_var_risk_sheet=True,\n",
        "                                               add_weights_turnover_sheet=True,\n",
        "                                               add_grouped_exposures=False,\n",
        "                                               add_grouped_cum_pnl=False,\n",
        "                                               add_weight_change_report=False,\n",
        "                                               add_current_signal_report=False,\n",
        "                                               add_instrument_history_report=True,\n",
        "                                               **fetch_default_report_kwargs(time_period=time_period))\n",
        "        qis.save_figs_to_pdf(figs=figs,\n",
        "                             file_name=f\"{portfolio_data.nav.name}_strategy_factsheet_long\",\n",
        "                             local_path=qis.local_path.get_output_path())\n",
        "\n",
        "    elif unit_test == UnitTests.EQUITY_BOND:\n",
        "        prices, benchmark_prices, group_data = fetch_equity_bond()\n",
        "        portfolio_data = generate_equity_bond_portfolio(prices=prices,\n",
        "                                                        weights=[0.6, 0.4],\n",
        "                                                        group_data=group_data,\n",
        "                                                        rebalancing_costs=rebalancing_costs)\n",
        "        figs = qis.generate_strategy_factsheet(portfolio_data=portfolio_data,\n",
        "                                               benchmark_prices=benchmark_prices,\n",
        "                                               add_grouped_exposures=True,\n",
        "                                               add_grouped_cum_pnl=True,\n",
        "                                               time_period=time_period,\n",
        "                                               **fetch_default_report_kwargs(time_period=time_period))\n",
        "        qis.save_figs_to_pdf(figs=figs,\n",
        "                             file_name=f\"{portfolio_data.nav.name}_portfolio_factsheet_long\",\n",
        "                             local_path=qis.local_path.get_output_path())\n",
        "\n",
        "    elif unit_test == UnitTests.DELTA1_STRATEGY:\n",
        "        from bbg_fetch import fetch_field_timeseries_per_tickers\n",
        "        prices = fetch_field_timeseries_per_tickers(tickers={'UISYMH5S Index': 'CDX_HY'})\n",
        "        benchmark_prices = fetch_field_timeseries_per_tickers(tickers={'HYG US Equity': 'HYG'})\n",
        "\n",
        "        delta1_portfolio = qis.backtest_model_portfolio(prices=prices,\n",
        "                                                        weights=np.array([1.0]),\n",
        "                                                        rebalancing_freq='SE',\n",
        "                                                        rebalancing_costs=rebalancing_costs,\n",
        "                                                        ticker='Delta1')\n",
        "        figs = qis.generate_strategy_factsheet(portfolio_data=delta1_portfolio,\n",
        "                                               benchmark_prices=benchmark_prices,\n",
        "                                               add_current_position_var_risk_sheet=False,\n",
        "                                               time_period=time_period,\n",
        "                                               **fetch_default_report_kwargs(time_period=time_period))\n",
        "        qis.save_figs_to_pdf(figs=figs,\n",
        "                             file_name=f\"delta1_strategy_factsheet\",\n",
        "                             local_path=qis.local_path.get_output_path())\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unit_test = UnitTests.VOLPARITY_PORTFOLIO\n",
        "    is_run_all_tests = False\n",
        "\n",
        "    if is_run_all_tests:\n",
        "        for unit_test in UnitTests:\n",
        "            run_unit_test(unit_test=unit_test)\n",
        "    else:\n",
        "        run_unit_test(unit_test=unit_test)"
      ],
      "metadata": {
        "id": "Rzry-jyrm4lL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}